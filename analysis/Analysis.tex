\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{enumitem}
\usepackage[hidelinks]{hyperref}
\usepackage[margin=1in]{geometry}

\setcounter{tocdepth}{2}

\begin{document}

\title{Analysis}
\date{}
\maketitle

\newpage
\tableofcontents

\newpage
\section{Sets}

\textbf{Definition:} A set is a collection of objects, called the \emph{elements} or \emph{members} of the set.  
We write $x \in X$ if $x$ is an element of the set $X$ and $x \notin X$ if $x$ is not an element of $X$.

Two sets $X = Y$, if
\[
x \in X \iff x \in Y
\]
(``iff'' or ``$\Leftrightarrow$'' both mean ``if and only if'').

The empty set is denoted by $\varnothing$, that is, the set without any elements.  
$X$ is \emph{nonempty} if it has at least one element.

We can define sets by listing their elements:
\[
X = \{a, b, c, d\}.
\]

We can also have infinite sets, for example:
\[
\mathbb{N} = \{1, 2, 3, \dots\}, \quad
\mathbb{N}_0 = \{0, 1, 2, 3, \dots\},
\]
\[
\mathbb{Z} = \{\dots, -3, -2, -1, 0, 1, 2, 3, \dots\}, \quad
\mathbb{Q} = \left\{ \tfrac{p}{q} : p, q \in \mathbb{Z}, \; q \neq 0 \right\},
\]
\[
\mathbb{R} = \{\text{all numbers with decimal expansions}\}.
\]

\subsection{Subsets}

$A$ is a subset of a set $X$ or $A$ is included in $X$, written $A \subseteq X$, if every element of $A$ belongs to $X$. $A$ is a proper subset of $X$, written as $A \subset X$, when $A \subseteq X$, but $A \neq X$.

\textbf{Def.:} The power set $\mathcal{P}$($X$) of a set $X$ is the set of all subsets of $X$.

\textbf{Ex.:} $X=$\{1,2,3\}, then $\mathcal{P}$($X$)=\{$\varnothing$,\{1\},\{2\},\{3\},\{1,2\},\{1,3\},\{2,3\},\{1,2,3\}\}

The power set $\mathcal{P}$($X$) of a set $X$ with |$X$|=$n$ elements has |$\mathcal{P}$($X$)|=$2^n$ elements because, in defining a subset, we have two independent choices for each element (does it belong to the subset or not?). Thus, the notation $2^X=\mathcal{P}(X)$ is also in use.

\subsection{Set operations}

The intersection $A\cap B$ of two sets $A$, $B$ is the set of all elements that belong to both $A$ and $B$. Two sets $A$, $B$ are said to be disjoint if $A\cap B = \varnothing $; that is, if $A$ and $B$ have no elements in common.

The union $A \cup B$ is the set of all elements that belong to $A$ or $B$. Note that we always use ‘or’ in an inclusive sense, so that $x \in A \cup B$ if $x$ is an element of $A$ or $B$, or both $A$ and $B$. (Thus, $A \cap B \subseteq A \cup B$.)

The set-difference of two sets $B$ and $A$ is the set of elements of $B$ that do not belong to $A$, that is $B \setminus A = \{x \in B:x \notin A\}$.
If we consider sets that are subsets of a fixed set $X$ (called the universe) that is understood from the context, then we write $A^c = \overline{A} = X \setminus A$ to denote the complement of $A \subseteq X$ in $X$. Note that $(A^c)^c = A$.

The Cartesian product $A \times B$ of sets $A$, $B$ is the set whose members all possible ordered pairs $(a, b)$ with $a\in A$, $b\in B$, thus $A\times B = \{(a,b):a\in A, b\in B \}$ and $|A\times B| = |A||B|$.

\subsection{Algebraic properties}

Intersection is a commutative operation $A\cap B = B \cap A$; and an \textit{associative} operation, that is:
\[
(A\cap B)\cap C = A \cap (B\cap C)\text{, thus} = A\cap B \cap C
\]
   both are also true for the union $A\cup B$.
Intersection distributes over union and union distributes over intersection:
\[
A\cap (B\cup C) = (A\cap B)\cup (A\cap C)
\]
\[
A\cup (B\cap C) = (A\cup B) \cap (A\cup C)
\]
We have De Morgan’s laws:
\[
(a\cup B)^c = A^c\cap B^c \text{ and } (A\cap B)^c = A^c\cup B^c
\]
Arbitrary many unions and intersections: Let $\mathcal{C}$ be a collection of sets. Then
\[
\bigcup\mathcal{C} = \bigcup_{A\in  \mathcal{C}}A = \{x: x \in A\text{, for some } A \in \mathcal{C}\}
\]
\[
\bigcap\mathcal{C} = \bigcap_{A\in  \mathcal{C}}A = \{x: x \in A\text{, for all } A \in \mathcal{C}\}
\]

\subsection{Relations}

Any subset of the Cartesian product of two sets $X$, $Y$ defines a (binary) relation $R \subseteq X \times Y $ between these two sets. Given $(x, y) \in R$ we may denote this inclusion simply as $xRy$. 
   Notation: $\forall$ means ‘for all’, $\exists$ means ‘exists’.
A binary relation $R$ is \textit{univalent} if
\[
\forall x \in X, \forall y \in Y, \forall z \in Y \text{ we have } ((x, y) \in R \text{ and } (x, z)\in R) \implies y = z
\]

A binary relation $R$ is \textit{total} if
\[
\forall x \in X, \exists y \in Y \text{ we have } (x,y) \in R
\]

\textbf{Def.:} A partially defined function is a univalent binary relation, and a function is a univalent and total binary relation. Thus a function $f: X \mapsto Y$ is defined by a univalent and total $xRy\iff y = f(x)$.
The set of all functions from $X$ to $Y$ is commonly denoted as 
\[
Y^X = \prod_{x\in X}Y
\]

\subsection{Orders and equivalences}

\textbf{Def.:} An order $\leq$ on a set $X$ is a binary relation on $X$, s.t. for every $x, y, z \in X$:
\begin{enumerate}
    \item $x \leq x$ (reflexivity),
    \item If $x \leq y$ and $y \leq x$ then $x=y$ (antisymmetry),
    \item If $x \leq y$ and $y\leq z$ then $x\leq z$ (transitivity).
\end{enumerate}


An order is \textit{linear} or \textit{total} if $\forall x,y\in X$ either $x\leq y$ or $y\leq x$. If $\leq$ is an order, then we define a strict order by $x < y$ if $x\leq y$ and $x\neq y$.

If for a relation $\sim$ in 2. instead of antisymmetry we have \textit{symmetry}: 
If $x\sim y$ then $y\sim x$
then $\sim$ is called an equivalence relation.

\section{Functions}

Per definition a function $f: X\mapsto Y$ is a univalent and total relation, that is for every $x\in X$ there is a unique $y = f(x)\in Y$. $Do(f) = X$ is called the \textit{domain} of $f$, and $Ran(f) = \{y \in Y: \exists x \in X, y = f(x)\}\subseteq Y$ is called the range of $f$. Also $f(A) = \{y\in Y:\exists x\in A, y = f(x)\}$ for some $A\subseteq X$.

\textbf{Ex.:} The identity function $id_X:X$ on a set $X$ is the function that maps every element of $X$ to itself, that is $id_X(x) = x$ for all $x\in X$.

\textbf{Ex.:} the characteristic or indicator function $\chi_A:X\mapsto \{0, 1\}$ of $A\subseteq X$ is defined as 
\[
\chi_{A}(x) =
\begin{cases}
1, & x \in A,\\
0, & x \notin A.
\end{cases}
\]
The graph of a function $f: X\mapsto Y$ is defined as
\[
G_f= \{(x, y)\in X\times Y:y = f(x)\}
\]

\subsection{Properties of functions}

A function $f: X\mapsto Y$ is
\begin{enumerate}
    \item injective (one-to-one) if it maps distinct elements to distinct elements, that is $x_1, x_2\in X$ and $x_1\neq x_2$ implies that $f(x_1)\neq f(x_2)$,
    \item surjective (onto) if its range $Ran(f)$ = Y, that is for every $y$ there exists an $x$, s.t. $y=f(x)$.
    \item If a function is both injective and surjective then its bijective.
\end{enumerate}

We define the composition $f\circ g(z) = f(g(z))$ of functions $f: Y\mapsto X$ and $g: Z\mapsto Y$. Note that we need the inclusion $Ran(g)\subseteq Do(f)$. $\circ$ is associative.

A bijective function $f: X\mapsto Y$ has an inverse $f^{-1}: Y\mapsto X$ defined by
\[
f^{-1}(y) = x \text{ if and only if } f(x) = y
\]
   that is $f\circ f^{-1} = id_Y$ and $f^{-1}\circ f = id_X$.
   
If $f: x\mapsto Y$ is merely injective than still $f: X\mapsto Ran(f)$ is bijective, thus invertible on its range with inverse $f^{-1}: Ran(f)\mapsto X$.

\subsection{Groups, monoids, fields}

\textbf{Def.:} Given a function $f: X\times X \mapsto X$ we may denote $f(x, y) = x * y$ and consider this as a binary operation on $X$. For example addition of integers is such an operation. The we say that * is/has

\begin{enumerate}
    \item Associative, if $x * (y * z) = (x * y) * z$,
    \item Commutative, if $x * y = y * x$,
    \item Neutral element, if there exists $e\in X$ (a neutral element), s.t. $x*e=e*x=x$,
    \item Inverse elements, if for all $x\in X$ there exists $x'\in X$ called an inverse of $x$, s.t. $x*x'=x'*x =e$ where $e$ is a neutral element.
\end{enumerate}

\textbf{Def.:} $(X, *)$ is called a
\begin{enumerate}
    \item Semigroup, if * is associative,
    \item Monoid, if $(X, *)$ is a semigroup and has a neutral element,
    \item Group, if $(X, *)$ is a monoid and every element $x\in X$ has an inverse.
\end{enumerate}

\textbf{Theorem:} In a group $(X, *)$ the neutral element $e\in X$ and inverse $x'$ for any fixed $x\in X$ are unique.

\textbf{Proof.:} Indeed, if there would be two neutral elements $e, e'$, then $e'=e*e'=e$. Also assuming $x*y=e=x*z$, implies $x'*(x*y)=x'*(x*z)$, that is $y=z=x'$.

Let $(X, \cdot, +)$ be given with binary operations $\cdot$ and $+$.

\textbf{Def.:} $(X, \cdot, +)$ is a field if
\begin{enumerate}
    \item $(X, \cdot, +)$ is a commutative group with neutral element 0,
    \item $(X\setminus \{0\}, \cdot)$ is a commutative group,
    \item $\cdot$ distributes over $+$ (distributivity), that is: $x\cdot (y+z) = x\cdot y + x\cdot z$.
In this case $+$ is usually called addition and $\cdot$ multiplication.
\end{enumerate}

\textbf{Ex.:} the rational numbers $\mathbb{Q}$ is a field, moreover an ordered field $(\mathbb{Q}, \cdot, +, \leq)$ equipped with the total order $x\leq y\iff0\leq y-x$, where 0 is the neutral element of $+$.

\textbf{Ex.:} the set of real numbers $\mathbb{R}$ is also a totally ordered field $(\mathbb{R}, \cdot, +, \leq)$

\textbf{Axiom:} the $\leq$ order of $\mathbb{R}$ satisfies
\begin{enumerate}[label=\Roman*.]
  \item $x\leq y$ implies $x+z\leq y+z$,
  \item $x< y$ and $z>0$ implies $xz<yz$.
\end{enumerate}

\subsection{Supremum and infimum}

\textbf{Def.:} A set $A\subseteq \mathbb{R}$ is \textit{bounded} \textit{from above}, if $\exists M\in \mathbb{R}$ s.t.  $x\leq M$ for all $x\in A$; and it is \textit{bounded from below}, if $\exists m\in \mathbb{R}$ s.t.  $x\geq m$ for all $x\in A$. If both holds for $A$, then it is bounded.				(‘s.t.’ is short hand for ‘such that’)

\textbf{Def.:} If $M\in \mathbb{R}$ is an upper bound of $A\subseteq \mathbb{R}$ s.t. for any other upper bound $M'\in \mathbb{R}$ of $A$ we have $M\leq M'$, then $M$ is called the least upper bound of $A$, denoted as
\[
M=\sup A
\]
Similarly, the greatest lower bound of $A\subseteq \mathbb{R}$, if exists, is denoted by 
\[
m=\inf A
\]
  meaning $m\geq m'$ for any lower bound $m$ of $A$.
If $A=\{x_i: i\in I\}\subseteq \mathbb{R}$ for an index set $I$, we also write:
\[
\sup A=\sup_{i\in I}x_i \text{ and } \inf A = \inf_{i\in I}x_i
\]

\textbf{Fact:} by the definition supremum and infimum of a set, if they exist, are both unique and $\sup A\geq \inf A$ for nonempty $A\subseteq \mathbb{R}$.

\textbf{Def.:} if $\sup A\in A$, then we call it the maximum of $A$ denoted by $\max A$, similarly if $\inf A \in A$, then we call it the minimum of $A$ denoted by $\min A$.

\textbf{Ex.:} Let $\mathbb{R}\supseteq A=\{{1\over n} : n\in \mathbb{N}\}$. Then $\sup A=1$ belongs to $A$, while $\inf A=0$ does not belong to $A$.

\textbf{Def.:} let us introduce the elements $\infty$,$-\infty$, so that $\infty >x>-\infty$ for any $x\in \mathbb{R}$ and define the extended real numbers as $\overline{\mathbb{R}}=\{\infty, -\infty\}\cup \mathbb{R}$. If a set $A\subseteq \mathbb{R}$ is not bounded from above then define $\sup A=\infty$, and if $A\subseteq \mathbb{R}$ is not bounded from below then define $\inf A=-\infty$. Also define $\sup \emptyset=-\infty$ and $\inf \emptyset = \infty$.

\subsection{(Order) Completeness}

Consider $A=\{x\in \mathbb{Q}:x^2\leq 2\}$. This set is bounded from above but has no least upper bound in $\mathbb{Q}$.

\textbf{Def(Completeness).:} a totally ordered field $Z$ is complete, if all nonempty upper bounded subsets of $Z$ have a least upper bound in $Z$. We call this the least upper bound property.

\textbf{Theorem(Dedekind):} There exists a unique (up to $(\cdot, +,\leq)$-preserving transformation) ordered complete field satisfying the order axioms I., II. that contains $\mathbb{Q}$ and it is the field $\mathbb{R}$.
Such a transformation $\phi:\mathbb{R}\mapsto \mathcal{M}$ satisfies $\phi(x+y)=\phi(x)+\phi(y), \phi(xy)=\phi(x)\phi(y), x\leq y \implies \phi(x)\leq \phi(y)$.


\subsection{Archimedean property}

\textbf{Theorem(Archimedean property):} If $x\in \mathbb{R}$, then there exists $n\in \mathbb{Z}$ such that $x<n$.

\textbf{Proof:} Suppose, for contradiction, that there exists $x\in \mathbb{R}$ s.t. $x>n$ for all $n\in \mathbb{Z}$. Then $x$ is an upper bound of $\mathbb{Z\subseteq\mathbb{R}}$, so $M=\sup\mathbb{Z}\in\mathbb{R}$ exists. Since $n\leq M$ for all $n\in \mathbb{Z}$, we have $n-1\leq M-1$ for all $n\in \mathbb{Z}$, which implies $n\leq M-1$ for all $n\in \mathbb{Z}$. But then $M-1$ is an upper bound of $\mathbb{Z}$ that is strictly less than $M=\sup \mathbb{Z}$, a contradiction to $M=\sup \mathbb{Z}$ being the least upper bound.

\textbf{Corollary:} For every $0<\epsilon\in \mathbb{R}$, there exists an $n\in \mathbb{N}$, s.t. $0<{1\over n}<\epsilon$.

\textbf{Corollary(integer part):} If $x\in \mathbb{R}$, then there exists $[x]=n\in \mathbb{Z}$ called the integer part of $x$, such that $n\leq x<n+1$.


\subsection{Further properties}

\textbf{Def(dense set).:} $A\subseteq \mathbb{R}$ is dense in $\mathbb{R}$, if for any $0<\epsilon, x\in \mathbb{R}$ there exists $a\in A$, s.t. $x-\epsilon<a<x+\epsilon$.

\textbf{Theorem(density of rationals):} $\mathbb{Q\subseteq\mathbb{R}}$ is dense in $\mathbb{R}$.

\textbf{Proof:} Let $0<\epsilon, x\in \mathbb{R}$. Then for any $n\in \mathbb{N}$ we have 
\[
[nx]\leq nx<[nx] + 1
\]
which gives
\[
{[nx]\over n}\leq x <{[nx]\over n} + {1\over n}
\]
Pick $n\in \mathbb{N}$, s.t. $0<{1\over n}<\epsilon$. Then we have
\[
{[nx]\over n}\leq x <{[nx]\over n} +{1\over n}<{[nx]\over n} +\epsilon
\]
which implies $x-\epsilon<{[nx]\over n} <x+\epsilon$ as wanted.

\subsection{Properties of sup and inf}

\textbf{Theorem:} 
\begin{enumerate}
    \item Given $A\in \mathbb{R}$, then $M=\sup A$ if and only if
    \begin{enumerate}
        \item $M$ is an upper bound of $A$, 
        \item for every $M' < M$ there exists $x\in A$ s.t. $M'<x$.
    \end{enumerate}
    \item If $A\subseteq B\subseteq \mathbb{R}$, then $\sup A\leq \sup B$ and $\inf B\leq \inf A$.
    \item If $A\subseteq \mathbb{R}$, then $\inf A\leq \sup A$.
    \item If $A\subseteq \mathbb{R}$, then $-\inf A = \sup (-A)$.
    \item If $A\subseteq \mathbb{R} \ni \alpha\geq 0$, then $\sup (\alpha A)=\alpha\sup (A)$.
    \item If $A, B \subseteq \mathbb{R}$, we have $\sup (A+B)\leq \sup A + \sup B$, $\inf (A+B)\geq \inf A+\inf B$ where $A+B=\{x\in \mathbb{R}:x=a+b, a\in A, b\in B\}$.
    \item Let $\mathcal{C}$ be a family of sets in $\mathbb{R}$, then $\sup (\cup \mathcal{C}) = \sup \{\sup A:A\in \mathcal{C}\}$.
\end{enumerate}

\subsection{Intervals and topology of $\mathbb{R}$}

\textbf{Def.:} Let $a, b \in \mathbb{R}$.
\begin{enumerate}
    \item Closed interval $[a, b]=\{x\in \mathbb{R}:a\leq x\leq b\}$,
    \item Open interval $(a, b)=\{x\in \mathbb{R}:a<x<b\}$,
    \item Half-open intervals $(a, b\text{]}=\{x\in \mathbb{R}:a<x\leq b\}, \text{[}a, b)=\{x\in \mathbb{R}:a\leq x < b\}$
    \item $\text{[}a, \infty)=\{x\in \mathbb{R}:a\leq x\}, (a, \infty)=\{x\in \mathbb{R}:a<x\}, (-\infty, b\text{]}=\{x\inf \mathbb{R}:b\geq x\}, (-\infty, b)=\{x\in \mathbb{R}:b>x\}$
\end{enumerate}

\textbf{Def.:} $A\subseteq \mathbb{R}$ is open if for every $x\in A$ there exists $0<\epsilon \in \mathbb{R}$ s.t. $(x-\epsilon, x+\epsilon)\subseteq A$.

\textbf{Def.:} $B\subseteq \mathbb{R}$ is closed if $B^C=\{x\in \mathbb{R}:x\notin B\}$ is open.

\textbf{Def.:} $U\subseteq \mathbb{R}$ is a neighborhood of $z\in \mathbb{R}$, if there exists $0<\epsilon \in \mathbb{R}$ s.t. $(z-\epsilon, z+\epsilon)\subseteq U$.

\textbf{Theorem:} Arbitrary union of open sets is open, and an intersection of finite number of open sets is open.

\textbf{Def.:} Let $A\subseteq \mathbb{R}$, then $x\in \mathbb{R}$ is
\begin{enumerate}
    \item an interior point of $a$, if there exists $0<\epsilon \in \mathbb{R}$ s.t. $(x-\epsilon, x+\epsilon)\subseteq A$;
    \item an isolated point of $A$, if $x\in A$ and there exists $0<\epsilon \in \mathbb{R}$ s.t. $x$ is the only point of $A$ that belongs to $(x-\epsilon, x+\epsilon)$; 
    \item a boundary point of $A$, if for every $0<\epsilon \in \mathbb{R}$ the interval $(x-\epsilon, x+\epsilon)$ contains at least a point in $A$ and at least a point not in $A$;
    \item an accumulation point of $A$, if for every $0<\epsilon \in \mathbb{R}$ the interval $(x-\epsilon, x+\epsilon)$ contains a point in $A$ distinct from $x$. 
\end{enumerate}

\section{Series}
\subsection{Series}

\textbf{Def(Convergence of a series).:} Let $(a_n)$ be a sequence of real numbers. The series
\[
\sum^{\infty}_{n=1}{a_n}
\]
converges to a sum $s\in \mathbb{R}$ if the sequence $(s_n)$ of partial sums
\[
s_k=\sum_{n=1}^{k}{a_n}
\]
converges to $s$ as $k\mapsto \infty$. Otherwise, the series diverges. If a series 
converges to $s$, we write 
\[
s=\sum_{n=1}^{\infty}{a_n}
\]
We also say a series diverges to $\pm \infty$ if its sequence of partial sums does.

\textbf{Proposition:} a series $\sum_{n=1}^{\infty}{a_n}$  with $a_n\geq 0$ converges iff $\exists M\geq 0$ s.t.
\[
s_k=\sum_{n=1}^{k}{a_n}\leq M
\]
for all $k\in \mathbb{N}$, that is $\{s_k\}_{k\in \mathbb{N}}$ is bounded from above; otherwise it 
diverges to $\infty$.

\textbf{Proof:} $a_n\geq 0$ implies that $(s_k)$ is monotone increasing, so by the Monotone Convergence Theorem its limit exists and is equal to $\sup \{s_k:l\in \mathbb{N}\}$.

\textbf{Theorem(Cauchy condition):} $\sum_{n=1}^{\infty}{a_n}$ converges iff $\forall \epsilon>0$ there exist $N\in \mathbb{N}$ s.t. $|\sum_{n=m+1}^{k}{a_n}| < \epsilon$ for all $m,k>N$.

\textbf{Proof:} $(s_k)$ converges iff $(s_k)$ is Cauchy, that is: $\forall \epsilon > 0$ there exist $N\in \mathbb{N}$ s.t. $|s_k-s_m|<\epsilon$ for all $m,k>N$ where $|s_k-s_m|=|\sum_{n=m+1}^{k}{a_n}|$.

\subsection{Basic conditions for convergence}

\textbf{Proposition:} if $\sum_{n=1}^{\infty}{a_n}$ converges, then $\lim_{n\to \infty}a_n=0$.

\textbf{Proof:} the series converges iff $(s_k)$ is Cauchy, so taking $m=k-1$ in the Cauchy condition we obtain that $|a_k|<\epsilon$ for all $k>N$, thus $a_k\to 0$.

\textbf{Note:} the converse of the above is not true! We will see soon that $a_n/to 0$ generally does not imply that $\sum_{n=1}^{\infty}{a_n}$ converges.

\subsection{Absolutely convergent series}

\textbf{Def(Absolute Convergence of a series).:} The series $\sum_{n=1}^{\infty}{a_n}$  converges absolutely if $\sum_{n=1}^{\infty}{|a_n|}$ converges, and $\sum_{n=1}^{\infty}{a_n}$ converges conditionally if $\sum_{n=1}^{\infty}{a_n}$ converges, but $\sum_{n=1}^{\infty}{|a_n|}$ diverges.

\textbf{Proposition:} if $\sum_{n=1}^{\infty}{a_n}$ converges absolutely, then $\sum_{n=1}^{\infty}{a_n}$ converges.

\textbf{Proof:} $\sum_{n=1}^{\infty}{|a_n|}$ is convergent, so $s_k=\sum_{n=1}^{k}{|a_n|}$ is Cauchy, which implies that $|\sum_{n=1}^{k}{a_n}|$ is also Cauchy by $|\sum_{n=m+1}^{k}{a_n}| \leq \sum_{n=m+1}^{k}{|a_n|}$, so the sequence of partial sums of $\sum_{n=1}^{\infty}{a_n}$ is Cauchy.

\subsection{Alternating series}

\textbf{Def(Alternating series).:} A series $\sum_{n=1}^{\infty}{a_n}$  is alternating if $a_na_{n+1} < 0$, that is, successive terms of $(a_n)$ have opposite signs.

\textbf{Theorem(Alternating series test):} Suppose that $(a_n)$ is a monotone decreasing sequence with $a_n\geq 0$ and also $\lim{n\to \infty}a_n=0$. Then the alternating sequence $\sum_{n=1}^{\infty}{(-1)^{n}a_n}$ converges.

\textbf{Proof:} $|\sum_{n=m+1}^{k}{(-1)^{n}a_n}|\leq a_{m+1}$ because $a_n\geq a_{n+1}\geq 0$, so $\lim{m\to \infty}a_{m+1}=0$ implies that the partial sums form a Cauchy sequence.

\textbf{Ex.:} $\sum_{n=1}^{\infty}{(-1)^{n}{1\over n}}$ converges.

\subsection{Rearrangement of a series}

\textbf{Def(rearrangement).:} A series $\sum_{n=1}^{\infty}{b_n}$ is a rearrangement of $\sum_{n=1}^{\infty}{a_n}$ if there is a bijective function $f:\mathbb{N}\mapsto \mathbb{N}$ s.t. $b_n=a_{f(n)}$.

\textbf{Theorem:} if a series is absolutely convergent, then every rearrangement of the series converges to the same sum.

\textbf{Proof:} First suppose that $a_n\geq 0$ and let $\sum_{n=1}^{\infty}{b_n}$  with $b_n=a_{f(n)}$ be a rearrangement. Given $\epsilon > 0$ there exist $n\in \mathbb{N}$ s.t. $0\leq \sum_{n=1}^{\infty}{a_n} - \sum_{n=1}^{N}{a_n}<\epsilon$. Since $f:\mathbb{N} \mapsto \mathbb{N}$ is bijective, there exists $M\in \mathbb{N}$ s.t. $\{1,2,...,N\}\subseteq f^{-1}(\{1,2,...,M\})$ meaning that $a_1, a_2, ..., a_N$ are all included among the $b_1, b_2, ..., b_M$. If $m>M$, then $\sum_{n=1}^{N}{a_n}\leq \sum_{n=1}^{m}{b_n}\leq \sum_{n=1}^{\infty}{a_n}$ and it follows that $0\leq \sum_{n=1}^{\infty}{a_n}-\sum_{n=1}^{m}{b_n}<\epsilon $, which proves the assertion.

The general case of the assertion follows from separating $\sum_{n=1}^{\infty}{a_n}$ into two sums of its positive and negative terms which are separately convergent because of absolute convergence of $\sum_{n=1}^{\infty}{a_n}$. Then any rearrangement splits into the rearrangements of the sums of the negative and positive terms of $\sum_{n=1}^{\infty}{a_n}$, so separately converge to the sums of the negative and positive terms of $\sum_{n=1}^{\infty}{a_n}$.

\textbf{Theorem:} if a series $\sum_{n=1}^{\infty}{a_n}$ is conditionally convergent, then it has rearrangements that converge to an arbitrary real number and rearrangements that diverge to $\infty$ or $-\infty$.

\textbf{Proof:} Since $\sum_{n=1}^{\infty}{a_n}$ is convergent, therefore $a_n\to 0$. Since $\sum_{n=1}^{\infty}{a_n}$ is only conditionally convergent, therefore the sums of its negative and positive parts are both divergent, otherwise the whole series would diverge if only one of them converged. This means that we can make sums of successive positive or negative terms in the series as large as we wish:

Let $s\in \mathbb{R}$. Starting from the beginning of the series, we choose successive positive or zero terms in the series until their partial sum is greater than or equal to $s$. Then we choose successive strictly negative terms, starting again from the beginning of the series, until the partial sum of all the terms is strictly less than $s$. After that, we choose successive positive or zero terms until the partial sum is greater than or equal $s$, followed by negative terms until the partial sum is strictly less than $s$, and so on. The partial sums are greater than $s$ by at most the value of the last positive term retained, and are less than $s$ by at most the value of the last negative term retained. Since $a_n\to 0$, it follows that the rearranged series converges to $s$. 

A similar argument shows that we can rearrange a conditional convergent series to diverge to $\infty$ or $-\infty$, and that we can rearrange the series so that it diverges in a finite or infinite oscillatory fashion.

\subsection{Comparison tests}

\textbf{Theorem(Comparison test):} Suppose that $b_n\geq 0$ and $\sum_{n=1}^{\infty}{b_n}$ converges. If $|a_n|\leq b_n$, then $\sum_{n=1}^{\infty}{a_n}$ converges absolutely. 
On the other hand, if $b_n\geq c_n \geq 0$ and $\sum_{n=1}^{\infty}{c_n}$ diverges, then $\sum_{n=1}^{\infty}{b_n}$ diverges as well.

\textbf{Proof:} $(\sum_{n=1}^{k}{b_n})_k$ is Cauchy, therefore $\sum_{n=m+1}^{k}{|a_n|}\leq \sum_{n=m+1}^{k}{b_n}$ implies that $(\sum_{n=1}^{k}{|a_n|})$ is Cauchy too. 
Similarly, $(\sum_{n=1}^{k}{c_n})_k$ is not Cauchy, therefore $\sum_{n=m+1}^{k}{c_n}\leq \sum_{n=m+1}^{k}{b_n}$ implies that $(\sum_{n=1}^{k}{b_n})_k$ is not Cauchy either, thus $\sum_{n=1}^{\infty}{b_n}$ diverges.

\textbf{Theorem(Limit Comparison test):} Suppose that we have two series $\sum_{n=1}^{\infty}{a_n}$ and $\sum_{n=1}^{\infty}{b_n}$ with $a_n\geq 0, b_n > 0$. If $\lim{n\to \infty}{a_n\over a_b}=c$ exists with $0<c<\infty$, then either both series converge or both diverge.

\textbf{Proof:} Given $\epsilon > 0$ there exist $N\in \mathbb{N}$ s.t. for all $n>N$ we have $x-\epsilon <{a_n\over b_n} < c + \epsilon$ implying $(c-\epsilon)b_n<a_n<(c+\epsilon)b_n$. By choosing $\epsilon>0$ sufficiently small we can assume that $c-\epsilon >0$. Then $(c-\epsilon)b_n<a_n<(c+\epsilon)b_n$ implies using the previous result that either both $(\sum_{n=1}^{k}{b_n})_k$ and $(\sum_{n=1}^{k}{a_n})$ are Cauchy or both of them are not Cauchy.


\subsection{Cauchy condensation test}
\subsection{Geometric series}
\subsection{Ratio test}
\subsection{Root test}


\end{document}